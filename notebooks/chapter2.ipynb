{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Coding Our First Neurons\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Single Neuron\n",
    "\n",
    "> The neuron sums each input multiplied by that input's weight, then adds the bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "# Calculating the output up to this point:\n",
    "output = (\n",
    "    inputs[0] * weights[0] +\n",
    "    inputs[1] * weights[1] +\n",
    "    inputs[2] * weights[2] +\n",
    "    bias\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we need to make a change to accept 4 inputs instead of 3.\n",
    "# We could do this by adding a new weight and a new input.\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "# These changes produce the following output:\n",
    "output = (\n",
    "    inputs[0] * weights[0] +\n",
    "    inputs[1] * weights[1] +\n",
    "    inputs[2] * weights[2] +\n",
    "    inputs[3] * weights[3] +\n",
    "    bias\n",
    ")\n",
    "# Notice a pattern in the calculation?\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Layer of Neurons\n",
    "\n",
    "> Neural networks typically have layers that consist of more than one neuron. These layers are nothing more than groups of neurons that take exactly the same input.\n",
    "\n",
    "> Note that the input provided to a given layer can either be training data (raw input) or the output of a previous layer. Each layer contains its own set of weights and its own bias. From this each layer produces its own unique output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have 4 initial inputs and a total of 3 layers:\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "bias1 = 2.0\n",
    "bias2 = 3.0\n",
    "bias3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# The resulting output for these layers will be a list of 3 values\n",
    "# (not a single value as before):\n",
    "outputs = [\n",
    "    # Neuron 1:\n",
    "    inputs[0] * weights1[0] +\n",
    "    inputs[1] * weights1[1] +\n",
    "    inputs[2] * weights1[2] +\n",
    "    inputs[3] * weights1[3] +\n",
    "    bias1,\n",
    "    \n",
    "    # Neuron 2:\n",
    "    inputs[0] * weights2[0] +\n",
    "    inputs[1] * weights2[1] +\n",
    "    inputs[2] * weights2[2] +\n",
    "    inputs[3] * weights2[3] +\n",
    "    bias2,\n",
    "    \n",
    "    # Neuron 3:\n",
    "    inputs[0] * weights3[0] +\n",
    "    inputs[1] * weights3[1] +\n",
    "    inputs[2] * weights3[2] +\n",
    "    inputs[3] * weights3[3] +\n",
    "    bias3\n",
    "]\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# Let's use a loop to scale and make our code more dynamic:\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Outputs of the current layer:\n",
    "layer_outputs = []\n",
    "# For each neuron:\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    # Zeroed output of given neuron:\n",
    "    neuron_output = 0\n",
    "    # For each input and weight to the neuron:\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        # Multiply this input by associated weight and add \n",
    "        # to the neuron's output variable:\n",
    "        neuron_output += n_input * weight\n",
    "    \n",
    "    # Add the bias:\n",
    "    neuron_output += neuron_bias\n",
    "    # Add the neuron's result to the layer's output list:\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors, Arrays, & Vectors\n",
    "\n",
    "> *A **tensor** object is an object that can be represented as an **array**.*\n",
    "\n",
    "> An **array** can be defined as an ordered *homologous* collection of numbers. This is the name of one of the main data structures in the NumPy package. Here is an example of a 3-dimensional array:\n",
    "\n",
    "```python\n",
    "[\n",
    "  [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "  ],\n",
    "  [\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "  ],\n",
    "  [\n",
    "    [13, 14, 15],\n",
    "    [16, 17, 18]\n",
    "  ]\n",
    "]\n",
    "```\n",
    "\n",
    "> Note that a list of lists is called **homologous** if each list along a dimension is identically long, for each dimension. For example:\n",
    "\n",
    "```python\n",
    "# This is homologous:\n",
    "[[1, 2, 3],\n",
    " [4, 5, 6],\n",
    " [7, 8, 9]]\n",
    "```\n",
    "\n",
    "```python\n",
    "# This is not homologous:\n",
    "[[1, 2, 3],\n",
    " [4, 5, 6],\n",
    " [7, 8]]\n",
    "```\n",
    "\n",
    "> A **vector** is considered a 1-dimensional array in NumPy, however in math it most closely resembles a list in Python.\n",
    "\n",
    "```python\n",
    "# This is a vector:\n",
    "[1, 2, 3]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product & Vector Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Continuing on concepts from the previous section, let's now discuss vector multiplication. This is one of the most important operations we'll perform on vectors.\n",
    "\n",
    "> When multiplying vectors, you can either perform a **dot product** or **cross product**. A cross product results in a vector while a dot product results in a scalar (a single value).\n",
    "\n",
    "> Due to the sheer number of variables and interconnections that can be made in neural networks, this allows us to model very complex and non-linear relationships due to non-linear activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<svg xlink=\"http://www.w3.org/1999/xlink\" width=\"210px\" height=\"96px\" viewBox=\"0 -2803.2 10920.9 4983.9\" role=\"img\" focusable=\"false\" style=\"vertical-align: -5.065ex;\" aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path><g transform=\"translate(1308,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g transform=\"translate(2182,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g transform=\"translate(3413,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g transform=\"translate(5248,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z\"></path><g transform=\"translate(251,-1912)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path><g transform=\"translate(428,0)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g transform=\"translate(1385,0)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g transform=\"translate(883,2006)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g transform=\"translate(8043,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path><g transform=\"translate(923,-260)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g><g transform=\"translate(9568,0)\"><path stroke-width=\"10\" transform=\"scale(1.73)\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path><g transform=\"translate(750,-260)\"><path stroke-width=\"10\" transform=\"scale(1.223)\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The **dot product** of two vectors is a sum of products of consecutive vector elements. It's important to note that each vector must be of the same size (have an equal number of elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# === Dot Product Example ===\n",
    "# Suppose we have two Python lists acting as vectors:\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "# Dot product calculation:\n",
    "dot_product = a[0] * b[0] + a[1] * b[1] + a[2] * b[2]\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, considering the example above, suppose we call *a* \"inputs\" and *b* \"weights\". Then suddenly the dot product looks like a convenient way to perform the operations we need, and have already performed in plain Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The addtion of two vectors is an operation performed element-wise, which means both vectors must be the same size. The result is a vector calculated as the sum of the consecutive vector elements, which will be the same size as the input vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Single Neuron with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Establish inputs, weights, and bias:\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "# Calculate the output:\n",
    "output = np.dot(weights, inputs) + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Layer of Neurons with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Establish inputs, weights, and bias:\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Calculate the outputs:\n",
    "outputs = np.dot(weights, inputs) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Batch of Data\n",
    "\n",
    "> To train, neural networks tend to receive data in **batches**. Although so far the example input data has only been on sample (or **observation**) or various features called a feature set, in practice we'll be working with batches of samples. This is because it is often faster to train in batches with parallel processing, but also batches help us with generalization during training.\n",
    "\n",
    "> Training in batches gives us a higher chance of making more meaningful changes to weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example batch of inputs:\n",
    "inputs = [\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Product\n",
    "\n",
    "> The matrix product is an operation in which we have two matrices, and we perform the dot product of all combinations of rows from the first matrix and the columns of the second matrix. This result is a matrix of those atomic dot products.\n",
    "\n",
    "> Important Note: The number of columns in the first matrix must be equal to the number of rows in the second matrix. Also, the resulting matrix will have the same number of rows as the first matrix and the same number of columns as the second matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition for the Matrix Product\n",
    "\n",
    "> We can use the relation of the dot product and the matrix product to say that the dot product of two vectors is equal to the matrix product of a row vector and a column vector (a transposed row vector).\n",
    "\n",
    "> Here we introduce a new operation called **transposition**. This is an operation that flips the rows and columns of a matrix. This is denoted by a superscript **T**.\n",
    "\n",
    "> A **row vector** is a matrix whose first dimension (the number of rows) is 1. A **column vector** is a matrix whose second dimension (the number of columns) is 1.\n",
    "\n",
    "```python\n",
    "# A row vector defined in NumPy:\n",
    "np.array([[1, 2, 3]])\n",
    "\n",
    "# A column vector defined in NumPy (note the transpose):\n",
    "np.array([[2, 3, 4]]).T\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "# Row vector:\n",
    "a = np.array([a])\n",
    "# Column vector:\n",
    "b = np.array([b]).T\n",
    "\n",
    "# Print the dot product:\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Layer of Neurons & Batch of Data with NumPy\n",
    "\n",
    "> Now let's combine concepts, creating a neural network calculation that takes in a group of samples (inputs) and outputs a group of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a group of samples:\n",
    "inputs = [\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Calculate the layer outputs:\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "print(layer_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
