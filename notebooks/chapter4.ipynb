{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Activation Functions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use different activation functions for different cases, so understanding how they work can help us properly pick which of them is best for a task.\n",
    "\n",
    "> The **activation function** is applied to the output of a neuron (or layer of neurons), which modifies outputs.\n",
    "\n",
    "> If an activation function itself is nonlinear, it allows for neural networks with multiple hidden layers to map nonlinear functions.\n",
    "\n",
    "> In general, neural networks will have two types of activation functions. Those used in hidden layers and those used in the output layer. Usually, the activation function used for the hidden neurons will be the same for all of them, but it doesn't have to be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "### The Step Activation Function\n",
    "\n",
    "> Recall the purpose this activation function serves is to mimic a neuron's \"firing\" or \"not firing\" based on input information. The simplest version of this is the **step function**. In a single neuron, if the `weights * inputs + bias` is greater than 0, the neuron fires, otherwise it doesn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "    - Historically used in hidden layers.\n",
    "    - Rarely chosen today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/step_function.png\" width=\"550\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### The Linear Activation Function\n",
    "\n",
    "> A **linear function** is simply the equation of a line. It is defined as `f(x) = x` or `y=x`.\n",
    "\n",
    "Summary:\n",
    "\n",
    "    - Usually applied to the last layer's output in a regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recall a regression model outputs a scalar value instead of a classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/linear_function.webp\" width=\"550\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "### The Sigmoid Activation Function\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
